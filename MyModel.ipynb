{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical,plot_model\n",
    "from tensorflow.keras import Model,optimizers,Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping, LearningRateScheduler,Callback,TensorBoard\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1650, 224, 224, 3), (1650,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "sub_list = os.listdir('CGR/CIP_CGR_outputs')\n",
    "X, Y = [], []\n",
    "for f in sub_list:\n",
    "    sub_file = os.path.join('CGR/CIP_CGR_outputs', f)\n",
    "    file_list = os.listdir(sub_file)\n",
    "    if f == '0':\n",
    "        Y += [0]*len(file_list)\n",
    "    if f == '1':\n",
    "        Y += [1]*len(file_list)\n",
    "    for name in file_list:\n",
    "        X.append(img_to_array(load_img(os.path.join(sub_file, name))))\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1024 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# patches=Patches(patch_size=7)(X[0].reshape(1,X.shape[1],X.shape[2],X.shape[3]))\n",
    "# n = int(np.sqrt(patches.shape[1]))\n",
    "# plt.figure(figsize=(4, 4))\n",
    "# for i, patch in enumerate(patches[0]):\n",
    "#     ax = plt.subplot(n, n, i + 1)\n",
    "#     patch_img = tf.reshape(patch, (7, 7, 3))\n",
    "#     plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "#     plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = s(num_heads=num_heads, key_dim=embed_dim, dropout=rate)\n",
    "        self.ffn = Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1650, 224, 224, 3), dtype('float32'), (1650, 2), dtype('float32'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
    "X=preprocess_input(X)\n",
    "Y=to_categorical(Y,2)\n",
    "X.shape,X.dtype,Y.shape,Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1320, 224, 224, 3), (330, 224, 224, 3), (1320, 2), (330, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=7)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drug_name='CIP'\n",
    "batch_size = 32\n",
    "classes = 2\n",
    "epochs = 100\n",
    "warm_up=int(epochs*0.8)\n",
    "verbosity = 1\n",
    "# max_seq_len=X.shape[1]\n",
    "lr=0.00001\n",
    "# img_size=X.shape[1]\n",
    "img_size=224\n",
    "# img_channel=X.shape[-1]\n",
    "img_channel=3\n",
    "# check_dir=f\"./results/{Bacteria}/{Encoding}\"\n",
    "# os.mkdir(check_dir)\n",
    "# if not os.path.exists(check_dir): os.mkdir(check_dir)\n",
    "# checkpoints=f\"./results/{Bacteria}/{Encoding}/{Bacteria}_{Mode}_{Encoding}_{Method}_{Drug_name}_BESTMODEL.h5\"\n",
    "checkpoints=f\"BESTMODEL.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2d_BN(x, nb_filter, kernel_size, strides=(1, 1), padding='same', name=None):\n",
    "    bn_name = (name + '_bn') if name else None\n",
    "    conv_name = name + '_conv' if name else None\n",
    "\n",
    "    x = layers.Conv2D(nb_filter, kernel_size, padding=padding, strides=strides, activation='relu', name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=3, name=bn_name)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BottleNeck(inputs,nb_filters,strides=(1,1),with_conv_shortcut=False):\n",
    "    k1,k2,k3=nb_filters\n",
    "    x = Conv2d_BN(inputs, nb_filter=k1, kernel_size=1, strides=strides, padding='same')\n",
    "    x = Conv2d_BN(x, nb_filter=k2, kernel_size=3, padding='same')\n",
    "    x = Conv2d_BN(x, nb_filter=k3, kernel_size=1, padding='same')\n",
    "    if with_conv_shortcut:\n",
    "        shortcut = Conv2d_BN(inputs, nb_filter=k3, strides=strides, kernel_size=1)\n",
    "        x = layers.add([x, shortcut])\n",
    "        return x\n",
    "    else:\n",
    "        x = layers.add([x, inputs])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "img_augmentation = Sequential(\n",
    "    [\n",
    "        preprocessing.RandomRotation(factor=0.01),\n",
    "        # preprocessing.RandomTranslation(height_factor=0.01, width_factor=0.01),\n",
    "        # preprocessing.RandomFlip(),\n",
    "        # preprocessing.RandomContrast(factor=0.01),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(img_size, img_size, img_channel))\n",
    "# x=img_augmentation(inputs)\n",
    "x = layers.ZeroPadding2D((3, 3))(inputs)\n",
    "x = Conv2d_BN(x, nb_filter=64, kernel_size=(7, 7), strides=(2, 2), padding='valid')\n",
    "x = layers. MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "x = BottleNeck(x, nb_filters=[64, 64, 256], strides=(1, 1), with_conv_shortcut=True)\n",
    "x = BottleNeck(x, nb_filters=[64, 64, 256])\n",
    "x = BottleNeck(x, nb_filters=[64, 64, 256])\n",
    "# x = BottleNeck(x, nb_filters=[128, 128, 512],strides=(2,2),with_conv_shortcut=True)\n",
    "# x = BottleNeck(x, nb_filters=[128, 128, 512])\n",
    "# x = BottleNeck(x, nb_filters=[128, 128, 512])\n",
    "# x = BottleNeck(x, nb_filters=[128, 128, 512])\n",
    "x = layers.AveragePooling2D(pool_size=(7, 7))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "# x=layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(classes, activation='softmax')(x)\n",
    "print(outputs.shape)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "  if epoch < warm_up:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(checkpoints, monitor='val_accuracy', verbose=verbosity, save_best_only=True, mode='max')\n",
    "LR_Scheduler = LearningRateScheduler(schedule=scheduler)\n",
    "tb = TensorBoard(log_dir='./TensorBoard', update_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/42 [..............................] - ETA: 0s - loss: 1.6951 - accuracy: 0.1875WARNING:tensorflow:From /home/amax/anaconda3/envs/torchhwk/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/42 [>.............................] - ETA: 1s - loss: 1.0310 - accuracy: 0.5469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0275s vs `on_train_batch_end` time: 0.0542s). Check your callbacks.\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.5567 - accuracy: 0.7886\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.24848, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 4s 92ms/step - loss: 0.5567 - accuracy: 0.7886 - val_loss: 0.7370 - val_accuracy: 0.2485\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.8788\n",
      "Epoch 00002: val_accuracy improved from 0.24848 to 0.61818, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 4s 87ms/step - loss: 0.2934 - accuracy: 0.8788 - val_loss: 0.6872 - val_accuracy: 0.6182\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2507 - accuracy: 0.9032\n",
      "Epoch 00003: val_accuracy improved from 0.61818 to 0.75152, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.2507 - accuracy: 0.9030 - val_loss: 0.5902 - val_accuracy: 0.7515\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2259 - accuracy: 0.9177\n",
      "Epoch 00004: val_accuracy did not improve from 0.75152\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.2265 - accuracy: 0.9174 - val_loss: 0.5586 - val_accuracy: 0.7515\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.9268\n",
      "Epoch 00005: val_accuracy did not improve from 0.75152\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.2095 - accuracy: 0.9273 - val_loss: 0.5998 - val_accuracy: 0.7515\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2033 - accuracy: 0.9299\n",
      "Epoch 00006: val_accuracy did not improve from 0.75152\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 0.2024 - accuracy: 0.9303 - val_loss: 0.7848 - val_accuracy: 0.7515\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1891 - accuracy: 0.9352\n",
      "Epoch 00007: val_accuracy did not improve from 0.75152\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.1905 - accuracy: 0.9348 - val_loss: 0.8537 - val_accuracy: 0.7515\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1857 - accuracy: 0.9421\n",
      "Epoch 00008: val_accuracy did not improve from 0.75152\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.1853 - accuracy: 0.9424 - val_loss: 1.0459 - val_accuracy: 0.7515\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.9439\n",
      "Epoch 00009: val_accuracy did not improve from 0.75152\n",
      "42/42 [==============================] - 3s 67ms/step - loss: 0.1800 - accuracy: 0.9439 - val_loss: 1.1100 - val_accuracy: 0.7515\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1642 - accuracy: 0.9505\n",
      "Epoch 00010: val_accuracy did not improve from 0.75152\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.1633 - accuracy: 0.9508 - val_loss: 1.0609 - val_accuracy: 0.7515\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1603 - accuracy: 0.9492\n",
      "Epoch 00011: val_accuracy did not improve from 0.75152\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.1603 - accuracy: 0.9492 - val_loss: 0.8673 - val_accuracy: 0.7515\n",
      "Epoch 12/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1636 - accuracy: 0.9451\n",
      "Epoch 00012: val_accuracy did not improve from 0.75152\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.1647 - accuracy: 0.9447 - val_loss: 0.8658 - val_accuracy: 0.7515\n",
      "Epoch 13/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1538 - accuracy: 0.9527\n",
      "Epoch 00013: val_accuracy did not improve from 0.75152\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.1541 - accuracy: 0.9523 - val_loss: 0.8228 - val_accuracy: 0.7515\n",
      "Epoch 14/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1449 - accuracy: 0.9566\n",
      "Epoch 00014: val_accuracy did not improve from 0.75152\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.1443 - accuracy: 0.9568 - val_loss: 0.7186 - val_accuracy: 0.7515\n",
      "Epoch 15/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1457 - accuracy: 0.9535\n",
      "Epoch 00015: val_accuracy did not improve from 0.75152\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.1451 - accuracy: 0.9538 - val_loss: 0.5886 - val_accuracy: 0.7515\n",
      "Epoch 16/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1341 - accuracy: 0.9566\n",
      "Epoch 00016: val_accuracy improved from 0.75152 to 0.92121, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.1374 - accuracy: 0.9553 - val_loss: 0.2475 - val_accuracy: 0.9212\n",
      "Epoch 17/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1818 - accuracy: 0.9284\n",
      "Epoch 00017: val_accuracy did not improve from 0.92121\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.1810 - accuracy: 0.9288 - val_loss: 0.3352 - val_accuracy: 0.9061\n",
      "Epoch 18/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1351 - accuracy: 0.9588\n",
      "Epoch 00018: val_accuracy did not improve from 0.92121\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.1352 - accuracy: 0.9583 - val_loss: 0.2551 - val_accuracy: 0.9152\n",
      "Epoch 19/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.9543\n",
      "Epoch 00019: val_accuracy did not improve from 0.92121\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.1536 - accuracy: 0.9538 - val_loss: 0.2180 - val_accuracy: 0.9212\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.9576\n",
      "Epoch 00020: val_accuracy did not improve from 0.92121\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.1249 - accuracy: 0.9576 - val_loss: 0.2336 - val_accuracy: 0.9212\n",
      "Epoch 21/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1293 - accuracy: 0.9649\n",
      "Epoch 00021: val_accuracy did not improve from 0.92121\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.1289 - accuracy: 0.9652 - val_loss: 0.2121 - val_accuracy: 0.9212\n",
      "Epoch 22/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1177 - accuracy: 0.9642\n",
      "Epoch 00022: val_accuracy improved from 0.92121 to 0.92727, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.1175 - accuracy: 0.9644 - val_loss: 0.2051 - val_accuracy: 0.9273\n",
      "Epoch 23/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1171 - accuracy: 0.9649\n",
      "Epoch 00023: val_accuracy improved from 0.92727 to 0.93030, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 0.1167 - accuracy: 0.9652 - val_loss: 0.2234 - val_accuracy: 0.9303\n",
      "Epoch 24/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1096 - accuracy: 0.9672\n",
      "Epoch 00024: val_accuracy did not improve from 0.93030\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.1091 - accuracy: 0.9674 - val_loss: 0.2040 - val_accuracy: 0.9242\n",
      "Epoch 25/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1098 - accuracy: 0.9680\n",
      "Epoch 00025: val_accuracy did not improve from 0.93030\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.1092 - accuracy: 0.9682 - val_loss: 0.2105 - val_accuracy: 0.9242\n",
      "Epoch 26/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0992 - accuracy: 0.9695\n",
      "Epoch 00026: val_accuracy improved from 0.93030 to 0.93636, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.0988 - accuracy: 0.9697 - val_loss: 0.1915 - val_accuracy: 0.9364\n",
      "Epoch 27/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 0.9756\n",
      "Epoch 00027: val_accuracy did not improve from 0.93636\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.1007 - accuracy: 0.9758 - val_loss: 0.2037 - val_accuracy: 0.9273\n",
      "Epoch 28/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1117 - accuracy: 0.9665\n",
      "Epoch 00028: val_accuracy did not improve from 0.93636\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.1111 - accuracy: 0.9667 - val_loss: 0.3177 - val_accuracy: 0.9212\n",
      "Epoch 29/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0997 - accuracy: 0.9703\n",
      "Epoch 00029: val_accuracy improved from 0.93636 to 0.93939, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.1001 - accuracy: 0.9697 - val_loss: 0.1978 - val_accuracy: 0.9394\n",
      "Epoch 30/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1011 - accuracy: 0.9710\n",
      "Epoch 00030: val_accuracy did not improve from 0.93939\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.1006 - accuracy: 0.9712 - val_loss: 0.1828 - val_accuracy: 0.9333\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9773\n",
      "Epoch 00031: val_accuracy did not improve from 0.93939\n",
      "42/42 [==============================] - 2s 60ms/step - loss: 0.0868 - accuracy: 0.9773 - val_loss: 0.1830 - val_accuracy: 0.9394\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9803\n",
      "Epoch 00032: val_accuracy did not improve from 0.93939\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0831 - accuracy: 0.9803 - val_loss: 0.2598 - val_accuracy: 0.9303\n",
      "Epoch 33/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0846 - accuracy: 0.9779\n",
      "Epoch 00033: val_accuracy did not improve from 0.93939\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0844 - accuracy: 0.9780 - val_loss: 0.2011 - val_accuracy: 0.9333\n",
      "Epoch 34/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0858 - accuracy: 0.9764\n",
      "Epoch 00034: val_accuracy improved from 0.93939 to 0.94545, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.0858 - accuracy: 0.9765 - val_loss: 0.1779 - val_accuracy: 0.9455\n",
      "Epoch 35/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0834 - accuracy: 0.9756\n",
      "Epoch 00035: val_accuracy did not improve from 0.94545\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0829 - accuracy: 0.9758 - val_loss: 0.1832 - val_accuracy: 0.9455\n",
      "Epoch 36/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0832 - accuracy: 0.9809\n",
      "Epoch 00036: val_accuracy did not improve from 0.94545\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.0859 - accuracy: 0.9803 - val_loss: 0.1847 - val_accuracy: 0.9394\n",
      "Epoch 37/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0786 - accuracy: 0.9825\n",
      "Epoch 00037: val_accuracy improved from 0.94545 to 0.95152, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 3s 83ms/step - loss: 0.0782 - accuracy: 0.9826 - val_loss: 0.1897 - val_accuracy: 0.9515\n",
      "Epoch 38/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0702 - accuracy: 0.9840\n",
      "Epoch 00038: val_accuracy did not improve from 0.95152\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0700 - accuracy: 0.9841 - val_loss: 0.1746 - val_accuracy: 0.9424\n",
      "Epoch 39/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0702 - accuracy: 0.9817\n",
      "Epoch 00039: val_accuracy improved from 0.95152 to 0.95455, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.0711 - accuracy: 0.9811 - val_loss: 0.1693 - val_accuracy: 0.9545\n",
      "Epoch 40/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0702 - accuracy: 0.9817\n",
      "Epoch 00040: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0700 - accuracy: 0.9818 - val_loss: 0.1659 - val_accuracy: 0.9485\n",
      "Epoch 41/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9863\n",
      "Epoch 00041: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0711 - accuracy: 0.9856 - val_loss: 0.1776 - val_accuracy: 0.9485\n",
      "Epoch 42/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 0.9809\n",
      "Epoch 00042: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0714 - accuracy: 0.9811 - val_loss: 0.1624 - val_accuracy: 0.9485\n",
      "Epoch 43/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0636 - accuracy: 0.9840\n",
      "Epoch 00043: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0633 - accuracy: 0.9841 - val_loss: 0.1642 - val_accuracy: 0.9485\n",
      "Epoch 44/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 0.9870\n",
      "Epoch 00044: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0659 - accuracy: 0.9871 - val_loss: 0.1645 - val_accuracy: 0.9455\n",
      "Epoch 45/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9855\n",
      "Epoch 00045: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0625 - accuracy: 0.9856 - val_loss: 0.1802 - val_accuracy: 0.9515\n",
      "Epoch 46/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 0.9863\n",
      "Epoch 00046: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0639 - accuracy: 0.9864 - val_loss: 0.2103 - val_accuracy: 0.9333\n",
      "Epoch 47/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0586 - accuracy: 0.9848\n",
      "Epoch 00047: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.0584 - accuracy: 0.9848 - val_loss: 0.1659 - val_accuracy: 0.9515\n",
      "Epoch 48/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0576 - accuracy: 0.9870\n",
      "Epoch 00048: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.0573 - accuracy: 0.9871 - val_loss: 0.1747 - val_accuracy: 0.9424\n",
      "Epoch 49/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9878\n",
      "Epoch 00049: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.0609 - accuracy: 0.9879 - val_loss: 0.2023 - val_accuracy: 0.9485\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9848\n",
      "Epoch 00050: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0610 - accuracy: 0.9848 - val_loss: 0.1701 - val_accuracy: 0.9455\n",
      "Epoch 51/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 0.9863\n",
      "Epoch 00051: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0633 - accuracy: 0.9864 - val_loss: 0.2102 - val_accuracy: 0.9485\n",
      "Epoch 52/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0727 - accuracy: 0.9840\n",
      "Epoch 00052: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.0723 - accuracy: 0.9841 - val_loss: 0.3528 - val_accuracy: 0.8455\n",
      "Epoch 53/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0603 - accuracy: 0.9848\n",
      "Epoch 00053: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0601 - accuracy: 0.9848 - val_loss: 0.2157 - val_accuracy: 0.9485\n",
      "Epoch 54/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9870\n",
      "Epoch 00054: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0562 - accuracy: 0.9871 - val_loss: 0.1778 - val_accuracy: 0.9394\n",
      "Epoch 55/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0780 - accuracy: 0.9771\n",
      "Epoch 00055: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0778 - accuracy: 0.9773 - val_loss: 0.3647 - val_accuracy: 0.8545\n",
      "Epoch 56/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9893\n",
      "Epoch 00056: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0576 - accuracy: 0.9894 - val_loss: 0.1940 - val_accuracy: 0.9515\n",
      "Epoch 57/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0574 - accuracy: 0.9870\n",
      "Epoch 00057: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0579 - accuracy: 0.9864 - val_loss: 0.1723 - val_accuracy: 0.9545\n",
      "Epoch 58/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9901\n",
      "Epoch 00058: val_accuracy did not improve from 0.95455\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.0481 - accuracy: 0.9902 - val_loss: 0.1688 - val_accuracy: 0.9545\n",
      "Epoch 59/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9901\n",
      "Epoch 00059: val_accuracy improved from 0.95455 to 0.95758, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.0577 - accuracy: 0.9902 - val_loss: 0.1643 - val_accuracy: 0.9576\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9894\n",
      "Epoch 00060: val_accuracy did not improve from 0.95758\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0507 - accuracy: 0.9894 - val_loss: 0.2172 - val_accuracy: 0.9485\n",
      "Epoch 61/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0544 - accuracy: 0.9870\n",
      "Epoch 00061: val_accuracy did not improve from 0.95758\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0541 - accuracy: 0.9871 - val_loss: 0.1756 - val_accuracy: 0.9545\n",
      "Epoch 62/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 0.9886\n",
      "Epoch 00062: val_accuracy improved from 0.95758 to 0.96061, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.0520 - accuracy: 0.9886 - val_loss: 0.1611 - val_accuracy: 0.9606\n",
      "Epoch 63/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9893\n",
      "Epoch 00063: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 0.0464 - accuracy: 0.9894 - val_loss: 0.2177 - val_accuracy: 0.9515\n",
      "Epoch 64/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 0.9863\n",
      "Epoch 00064: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0599 - accuracy: 0.9864 - val_loss: 0.2247 - val_accuracy: 0.9545\n",
      "Epoch 65/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9893\n",
      "Epoch 00065: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0463 - accuracy: 0.9894 - val_loss: 0.2021 - val_accuracy: 0.9333\n",
      "Epoch 66/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0471 - accuracy: 0.9893\n",
      "Epoch 00066: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0469 - accuracy: 0.9894 - val_loss: 0.1904 - val_accuracy: 0.9545\n",
      "Epoch 67/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0444 - accuracy: 0.9893\n",
      "Epoch 00067: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0442 - accuracy: 0.9894 - val_loss: 0.2224 - val_accuracy: 0.9515\n",
      "Epoch 68/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9916\n",
      "Epoch 00068: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 0.0388 - accuracy: 0.9917 - val_loss: 0.2463 - val_accuracy: 0.9515\n",
      "Epoch 69/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9893\n",
      "Epoch 00069: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.0464 - accuracy: 0.9894 - val_loss: 0.2100 - val_accuracy: 0.9545\n",
      "Epoch 70/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.9893\n",
      "Epoch 00070: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.0581 - accuracy: 0.9894 - val_loss: 0.2437 - val_accuracy: 0.9515\n",
      "Epoch 71/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0441 - accuracy: 0.9901\n",
      "Epoch 00071: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.0439 - accuracy: 0.9902 - val_loss: 0.1871 - val_accuracy: 0.9545\n",
      "Epoch 72/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9901\n",
      "Epoch 00072: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0470 - accuracy: 0.9894 - val_loss: 0.2009 - val_accuracy: 0.9303\n",
      "Epoch 73/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0442 - accuracy: 0.9916\n",
      "Epoch 00073: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0441 - accuracy: 0.9917 - val_loss: 0.1821 - val_accuracy: 0.9424\n",
      "Epoch 74/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9916\n",
      "Epoch 00074: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0447 - accuracy: 0.9917 - val_loss: 0.1623 - val_accuracy: 0.9576\n",
      "Epoch 75/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9909\n",
      "Epoch 00075: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0466 - accuracy: 0.9909 - val_loss: 0.2200 - val_accuracy: 0.9394\n",
      "Epoch 76/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9909\n",
      "Epoch 00076: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0389 - accuracy: 0.9909 - val_loss: 0.1740 - val_accuracy: 0.9545\n",
      "Epoch 77/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 0.9886\n",
      "Epoch 00077: val_accuracy did not improve from 0.96061\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0498 - accuracy: 0.9886 - val_loss: 0.1690 - val_accuracy: 0.9606\n",
      "Epoch 78/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0421 - accuracy: 0.9916\n",
      "Epoch 00078: val_accuracy improved from 0.96061 to 0.96364, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.0419 - accuracy: 0.9917 - val_loss: 0.1761 - val_accuracy: 0.9636\n",
      "Epoch 79/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0472 - accuracy: 0.9886\n",
      "Epoch 00079: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0470 - accuracy: 0.9886 - val_loss: 0.1739 - val_accuracy: 0.9606\n",
      "Epoch 80/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9916\n",
      "Epoch 00080: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 0.0434 - accuracy: 0.9917 - val_loss: 0.2087 - val_accuracy: 0.9515\n",
      "Epoch 81/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9924\n",
      "Epoch 00081: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 0.0434 - accuracy: 0.9924 - val_loss: 0.1973 - val_accuracy: 0.9545\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9917\n",
      "Epoch 00082: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 0.0378 - accuracy: 0.9917 - val_loss: 0.2874 - val_accuracy: 0.9485\n",
      "Epoch 83/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9924\n",
      "Epoch 00083: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 0.0373 - accuracy: 0.9924 - val_loss: 0.2146 - val_accuracy: 0.9545\n",
      "Epoch 84/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9916\n",
      "Epoch 00084: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 0.0361 - accuracy: 0.9917 - val_loss: 0.1819 - val_accuracy: 0.9515\n",
      "Epoch 85/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0334 - accuracy: 0.9924\n",
      "Epoch 00085: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0332 - accuracy: 0.9924 - val_loss: 0.2021 - val_accuracy: 0.9545\n",
      "Epoch 86/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0554 - accuracy: 0.9886\n",
      "Epoch 00086: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0551 - accuracy: 0.9886 - val_loss: 0.1649 - val_accuracy: 0.9606\n",
      "Epoch 87/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9916\n",
      "Epoch 00087: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.0365 - accuracy: 0.9917 - val_loss: 0.2397 - val_accuracy: 0.9545\n",
      "Epoch 88/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9916\n",
      "Epoch 00088: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.0348 - accuracy: 0.9917 - val_loss: 0.2777 - val_accuracy: 0.9485\n",
      "Epoch 89/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 0.9916\n",
      "Epoch 00089: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0391 - accuracy: 0.9917 - val_loss: 0.2013 - val_accuracy: 0.9545\n",
      "Epoch 90/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9916\n",
      "Epoch 00090: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0332 - accuracy: 0.9917 - val_loss: 0.1929 - val_accuracy: 0.9576\n",
      "Epoch 91/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9924\n",
      "Epoch 00091: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.0322 - accuracy: 0.9924 - val_loss: 0.1897 - val_accuracy: 0.9606\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9909\n",
      "Epoch 00092: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0361 - accuracy: 0.9909 - val_loss: 0.1857 - val_accuracy: 0.9576\n",
      "Epoch 93/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9924\n",
      "Epoch 00093: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0347 - accuracy: 0.9924 - val_loss: 0.1736 - val_accuracy: 0.9636\n",
      "Epoch 94/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9916\n",
      "Epoch 00094: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0316 - accuracy: 0.9917 - val_loss: 0.2243 - val_accuracy: 0.9515\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9924\n",
      "Epoch 00095: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0327 - accuracy: 0.9924 - val_loss: 0.1958 - val_accuracy: 0.9576\n",
      "Epoch 96/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9924\n",
      "Epoch 00096: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 0.0313 - accuracy: 0.9924 - val_loss: 0.1965 - val_accuracy: 0.9576\n",
      "Epoch 97/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9931\n",
      "Epoch 00097: val_accuracy did not improve from 0.96364\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0316 - accuracy: 0.9924 - val_loss: 0.1993 - val_accuracy: 0.9576\n",
      "Epoch 98/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9924\n",
      "Epoch 00098: val_accuracy improved from 0.96364 to 0.96667, saving model to BESTMODEL.h5\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.0336 - accuracy: 0.9924 - val_loss: 0.1761 - val_accuracy: 0.9667\n",
      "Epoch 99/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0321 - accuracy: 0.9916\n",
      "Epoch 00099: val_accuracy did not improve from 0.96667\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 0.0319 - accuracy: 0.9917 - val_loss: 0.2082 - val_accuracy: 0.9545\n",
      "Epoch 100/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9939\n",
      "Epoch 00100: val_accuracy did not improve from 0.96667\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 0.0317 - accuracy: 0.9932 - val_loss: 0.1915 - val_accuracy: 0.9606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f46105c1208>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=verbosity,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[checkpointer, LR_Scheduler, tb]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for CIP\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           S       0.96      0.99      0.98       248\n",
      "           R       0.97      0.89      0.93        82\n",
      "\n",
      "    accuracy                           0.97       330\n",
      "   macro avg       0.97      0.94      0.95       330\n",
      "weighted avg       0.97      0.97      0.97       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=load_model(checkpoints)\n",
    "preds=model.predict(x_test)\n",
    "print(\"Result for {}\".format(Drug_name))\n",
    "print(classification_report(y_test.argmax(-1),preds.argmax(-1),target_names=['S','R']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9e83ed16f81a8e2145c5b76006e38f35c412e8be0cae4deba529a0756310e81"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('torchhwk': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
