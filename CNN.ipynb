{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical,plot_model\n",
    "from tensorflow.keras import Model,optimizers,Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping, LearningRateScheduler,Callback,TensorBoard\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Method='CNN_FCGR'\n",
    "Encoding='FCGR'\n",
    "Drug_name='GEN'\n",
    "Bacteria='E.coli'\n",
    "seed=7\n",
    "Mode='ToN'\n",
    "sampling=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. dataset from npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1650, 100, 100), dtype('float32'), (1650,), dtype('int64'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data=np.load(f'data/{Bacteria}/preprocessed/{Encoding}/{Bacteria}_{Mode}_{Encoding}_{Drug_name}.npz')\n",
    "X,Y=data['X'],data['Y']\n",
    "X.shape,X.dtype,Y.shape,Y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. dataset from raw_cgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "# sub_list = os.listdir(f'{Drug_name}_CGR_outputs')\n",
    "# X, Y = [], []\n",
    "# for f in sub_list:\n",
    "#     sub_file = os.path.join(f'{Drug_name}_CGR_outputs', f)\n",
    "#     file_list = os.listdir(sub_file)\n",
    "#     if f == '0':\n",
    "#         Y += [0]*len(file_list)\n",
    "#     if f == '1':\n",
    "#         Y += [1]*len(file_list)\n",
    "#     for name in file_list:\n",
    "#         X.append(img_to_array(load_img(os.path.join(sub_file, name))))\n",
    "# X = np.array(X)\n",
    "# Y = np.array(Y)\n",
    "# X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(X.shape)==3: X=X.reshape(-1,100,100,1)\n",
    "# X=preprocess_input(X)\n",
    "# Y=to_categorical(Y,2)\n",
    "# X.shape,X.dtype,Y.shape,Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(X, Y, sampling=True):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "    if sampling:\n",
    "        # sample_solver = BorderlineSMOTE()\n",
    "        sample_solver =EditedNearestNeighbours()\n",
    "        x_samp, y_samp = x_train.reshape(x_train.shape[0], -1), y_train\n",
    "        x_samp, y_samp = sample_solver.fit_resample(x_samp, y_samp)\n",
    "        x_samp, y_samp = x_samp.reshape(-1, x_train.shape[1], x_train.shape[2], x_train.shape[3]), y_samp\n",
    "        return x_samp, y_samp, x_test, y_test\n",
    "    else:\n",
    "        return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1126, 100, 100, 1), (330, 100, 100, 1), (1126,), (330,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(X.shape)==3: X=X.reshape(-1,100,100,1)\n",
    "X=preprocess_input(X)\n",
    "x_samp,y_samp,x_test,y_test=sample(X,Y,sampling=sampling)\n",
    "x_samp.shape,x_test.shape,y_samp.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_samp=to_categorical(y_samp,2)\n",
    "y_test=to_categorical(y_test,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((165, 100, 100, 1), (165, 100, 100, 1), (165, 2), (165, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val,x_test,y_val,y_test=train_test_split(x_test,y_test,test_size=0.5,random_state=seed)\n",
    "x_val.shape,x_test.shape,y_val.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=seed)\n",
    "# x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "classes = 2\n",
    "epochs = 100\n",
    "warm_up=int(epochs*0.8)\n",
    "verbosity = 1\n",
    "# max_seq_len=X.shape[1]\n",
    "lr=1e-5\n",
    "# lr=3e-6#CTX\n",
    "img_size=X.shape[1]\n",
    "img_channel=X.shape[-1]\n",
    "# check_dir=f\"./results/{Bacteria}/{Encoding}\"\n",
    "# os.mkdir(check_dir)\n",
    "# if not os.path.exists(check_dir): os.mkdir(check_dir)\n",
    "# checkpoints=f\"./results/{Bacteria}/{Encoding}/{Bacteria}_{Mode}_{Encoding}_{Method}_{Drug_name}_BESTMODEL.h5\"\n",
    "checkpoints=f\"BESTMODEL.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_augmentation = Sequential(\n",
    "    [\n",
    "        preprocessing.RandomRotation(factor=0.01),\n",
    "        # preprocessing.RandomTranslation(height_factor=0.01, width_factor=0.01),\n",
    "        # preprocessing.RandomFlip(),\n",
    "        # preprocessing.RandomContrast(factor=0.01),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2d_BN(x, nb_filter, kernel_size, strides=(1, 1), padding='same', name=None):\n",
    "    bn_name = (name + '_bn') if name else None\n",
    "    conv_name = name + '_conv' if name else None\n",
    "\n",
    "    x = layers.Conv2D(nb_filter, kernel_size, padding=padding, strides=strides, activation='relu', name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=3, name=bn_name)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BottleNeck(inputs,nb_filters,strides=(1,1),with_conv_shortcut=False):\n",
    "    k1,k2,k3=nb_filters\n",
    "    x = Conv2d_BN(inputs, nb_filter=k1, kernel_size=1, strides=strides, padding='same')\n",
    "    x = Conv2d_BN(x, nb_filter=k2, kernel_size=3, padding='same')\n",
    "    x = Conv2d_BN(x, nb_filter=k3, kernel_size=1, padding='same')\n",
    "    if with_conv_shortcut:\n",
    "        shortcut = Conv2d_BN(inputs, nb_filter=k3, strides=strides, kernel_size=1)\n",
    "        x = layers.add([x, shortcut])\n",
    "        return x\n",
    "    else:\n",
    "        x = layers.add([x, inputs])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(img_size, img_size, img_channel))\n",
    "# x=img_augmentation(inputs)\n",
    "x = layers.ZeroPadding2D((3, 3))(inputs)\n",
    "x = Conv2d_BN(x, nb_filter=64, kernel_size=(7, 7), strides=(2, 2), padding='valid')\n",
    "x = layers. MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "x = BottleNeck(x, nb_filters=[64, 64, 256], strides=(1, 1), with_conv_shortcut=True)\n",
    "x = BottleNeck(x, nb_filters=[64, 64, 256])\n",
    "x = BottleNeck(x, nb_filters=[64, 64, 256])\n",
    "# x = BottleNeck(x, nb_filters=[128, 128, 512],strides=(2,2),with_conv_shortcut=True)\n",
    "# x = BottleNeck(x, nb_filters=[128, 128, 512])\n",
    "# x = BottleNeck(x, nb_filters=[128, 128, 512])\n",
    "# x = BottleNeck(x, nb_filters=[128, 128, 512])\n",
    "x = layers.AveragePooling2D(pool_size=(7, 7))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "# x=layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(classes, activation='softmax')(x)\n",
    "print(outputs.shape)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# resnet = ResNet50V2(weights=None, include_top=True, input_shape=(img_size, img_size, img_channel), pooling='max', classes=classes)\n",
    "# # # resnet = ResNet50V2(weights=None, include_top=False, input_shape=(100, 100, 1), pooling='max')\n",
    "# # # resnet=ResNet50V2(classes=2,weights=None,include_top=True)\n",
    "# # resnet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = layers.Input(shape=(img_size, img_size, img_channel))\n",
    "# # x=img_augmentation(inputs)\n",
    "# outputs = resnet(inputs)\n",
    "# # x = resnet(inputs)\n",
    "# # x = layers.Dense(units=512, activation='relu')(x)\n",
    "# # x = layers.Dropout(rate=0.2)(x)\n",
    "# # outputs = layers.Dense(units=classes, activation='softmax')(x)\n",
    "# model = Model(inputs=inputs, outputs=outputs)\n",
    "# model.compile(optimizer=optimizers.Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs=layers.Input(shape=(img_size,img_size,img_channel))\n",
    "# x=img_augmentation(inputs)\n",
    "# x=layers.Conv2D(filters=8, kernel_size=3,activation='relu')(x)\n",
    "# x=BatchNormalization()(x)\n",
    "# print(x.shape)\n",
    "# x=layers.Conv2D(filters=8, kernel_size=3, padding='same',activation='relu')(x)\n",
    "# # x=BatchNormalization()(x)\n",
    "# x=layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x=layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu')(x)\n",
    "# x=layers.BatchNormalization()(x)\n",
    "# x=layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu')(x)\n",
    "# x=layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x=layers.Flatten()(x)\n",
    "# # print(x.shape)\n",
    "# x=layers.Dense(128, activation='relu')(x)\n",
    "# # x=layers.Dropout(rate=0.2)(x)\n",
    "# outputs=layers.Dense(units=classes, activation='softmax')(x)\n",
    "# # outputs=Dense(units=no_classes, activation='sigmoid')(x)\n",
    "# model=Model(inputs=inputs,outputs=outputs)\n",
    "# model.compile(optimizer=optimizers.Adam(learning_rate=lr),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "  if epoch < warm_up:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(checkpoints, monitor='val_accuracy', verbose=verbosity, save_best_only=True, mode='max')\n",
    "# earlystopper=EarlyStopping(monitor='val_accuracy',min_delta=0.0001,patience=5,verbose=1)\n",
    "LR_Scheduler = LearningRateScheduler(schedule=scheduler)\n",
    "tb = TensorBoard(log_dir='./TensorBoard', update_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.7764 - accuracy: 0.1562WARNING:tensorflow:From /home/amax/anaconda3/envs/torchhwk/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/36 [>.............................] - ETA: 2s - loss: 0.7204 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0319s vs `on_train_batch_end` time: 0.0828s). Check your callbacks.\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.8366\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81818, saving model to BESTMODEL.h5\n",
      "36/36 [==============================] - 2s 69ms/step - loss: 0.4333 - accuracy: 0.8366 - val_loss: 0.6373 - val_accuracy: 0.8182\n",
      "Epoch 2/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3603 - accuracy: 0.8695\n",
      "Epoch 00002: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.3638 - accuracy: 0.8686 - val_loss: 0.5940 - val_accuracy: 0.8182\n",
      "Epoch 3/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3567 - accuracy: 0.8704\n",
      "Epoch 00003: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.3536 - accuracy: 0.8721 - val_loss: 0.5387 - val_accuracy: 0.8182\n",
      "Epoch 4/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3488 - accuracy: 0.8713\n",
      "Epoch 00004: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.3484 - accuracy: 0.8721 - val_loss: 0.5204 - val_accuracy: 0.8182\n",
      "Epoch 5/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3461 - accuracy: 0.8658\n",
      "Epoch 00005: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.3430 - accuracy: 0.8677 - val_loss: 0.4994 - val_accuracy: 0.8182\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.8739\n",
      "Epoch 00006: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.3364 - accuracy: 0.8739 - val_loss: 0.4870 - val_accuracy: 0.8182\n",
      "Epoch 7/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.3335 - accuracy: 0.8723\n",
      "Epoch 00007: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3324 - accuracy: 0.8730 - val_loss: 0.4794 - val_accuracy: 0.8182\n",
      "Epoch 8/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3242 - accuracy: 0.8732\n",
      "Epoch 00008: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3274 - accuracy: 0.8721 - val_loss: 0.4751 - val_accuracy: 0.8182\n",
      "Epoch 9/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.3252 - accuracy: 0.8723\n",
      "Epoch 00009: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.3242 - accuracy: 0.8730 - val_loss: 0.4745 - val_accuracy: 0.8182\n",
      "Epoch 10/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3278 - accuracy: 0.8704\n",
      "Epoch 00010: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.3241 - accuracy: 0.8721 - val_loss: 0.4726 - val_accuracy: 0.8182\n",
      "Epoch 11/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.3155 - accuracy: 0.8714\n",
      "Epoch 00011: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.3153 - accuracy: 0.8712 - val_loss: 0.4739 - val_accuracy: 0.8182\n",
      "Epoch 12/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3229 - accuracy: 0.8704\n",
      "Epoch 00012: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3250 - accuracy: 0.8694 - val_loss: 0.4753 - val_accuracy: 0.8182\n",
      "Epoch 13/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.3203 - accuracy: 0.8693\n",
      "Epoch 00013: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.3176 - accuracy: 0.8721 - val_loss: 0.4705 - val_accuracy: 0.8182\n",
      "Epoch 14/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3073 - accuracy: 0.8741\n",
      "Epoch 00014: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3111 - accuracy: 0.8721 - val_loss: 0.4690 - val_accuracy: 0.8182\n",
      "Epoch 15/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3041 - accuracy: 0.8713\n",
      "Epoch 00015: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.3048 - accuracy: 0.8712 - val_loss: 0.4659 - val_accuracy: 0.8182\n",
      "Epoch 16/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3020 - accuracy: 0.8741\n",
      "Epoch 00016: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.3033 - accuracy: 0.8739 - val_loss: 0.4536 - val_accuracy: 0.8182\n",
      "Epoch 17/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2936 - accuracy: 0.8750\n",
      "Epoch 00017: val_accuracy did not improve from 0.81818\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.3007 - accuracy: 0.8721 - val_loss: 0.4617 - val_accuracy: 0.8182\n",
      "Epoch 18/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3002 - accuracy: 0.8704\n",
      "Epoch 00018: val_accuracy improved from 0.81818 to 0.82424, saving model to BESTMODEL.h5\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.2979 - accuracy: 0.8712 - val_loss: 0.4515 - val_accuracy: 0.8242\n",
      "Epoch 19/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2973 - accuracy: 0.8750\n",
      "Epoch 00019: val_accuracy did not improve from 0.82424\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.2992 - accuracy: 0.8721 - val_loss: 0.4424 - val_accuracy: 0.8061\n",
      "Epoch 20/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.3003 - accuracy: 0.8750\n",
      "Epoch 00020: val_accuracy improved from 0.82424 to 0.83030, saving model to BESTMODEL.h5\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.3001 - accuracy: 0.8748 - val_loss: 0.4376 - val_accuracy: 0.8303\n",
      "Epoch 21/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.3044 - accuracy: 0.8687\n",
      "Epoch 00021: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3033 - accuracy: 0.8694 - val_loss: 0.4151 - val_accuracy: 0.8242\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.8730\n",
      "Epoch 00022: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2942 - accuracy: 0.8730 - val_loss: 0.4364 - val_accuracy: 0.8061\n",
      "Epoch 23/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2947 - accuracy: 0.8679\n",
      "Epoch 00023: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2950 - accuracy: 0.8677 - val_loss: 0.4048 - val_accuracy: 0.8242\n",
      "Epoch 24/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2952 - accuracy: 0.8732\n",
      "Epoch 00024: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2945 - accuracy: 0.8739 - val_loss: 0.3982 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2844 - accuracy: 0.8732\n",
      "Epoch 00025: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.2871 - accuracy: 0.8721 - val_loss: 0.4113 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2972 - accuracy: 0.8658\n",
      "Epoch 00026: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2916 - accuracy: 0.8703 - val_loss: 0.4010 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2745 - accuracy: 0.8787\n",
      "Epoch 00027: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2845 - accuracy: 0.8739 - val_loss: 0.3875 - val_accuracy: 0.8061\n",
      "Epoch 28/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2883 - accuracy: 0.8759\n",
      "Epoch 00028: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.2887 - accuracy: 0.8757 - val_loss: 0.3975 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.8739\n",
      "Epoch 00029: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.2849 - accuracy: 0.8739 - val_loss: 0.3892 - val_accuracy: 0.8061\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2845 - accuracy: 0.8694\n",
      "Epoch 00030: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2845 - accuracy: 0.8694 - val_loss: 0.3962 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2846 - accuracy: 0.8741\n",
      "Epoch 00031: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2842 - accuracy: 0.8739 - val_loss: 0.3910 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2796 - accuracy: 0.8712\n",
      "Epoch 00032: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2838 - accuracy: 0.8694 - val_loss: 0.3854 - val_accuracy: 0.8061\n",
      "Epoch 33/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2860 - accuracy: 0.8714\n",
      "Epoch 00033: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2867 - accuracy: 0.8712 - val_loss: 0.3912 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2830 - accuracy: 0.8713\n",
      "Epoch 00034: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2817 - accuracy: 0.8721 - val_loss: 0.3942 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2806 - accuracy: 0.8750\n",
      "Epoch 00035: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2814 - accuracy: 0.8748 - val_loss: 0.3908 - val_accuracy: 0.8061\n",
      "Epoch 36/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2806 - accuracy: 0.8723\n",
      "Epoch 00036: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2795 - accuracy: 0.8730 - val_loss: 0.4044 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2810 - accuracy: 0.8693\n",
      "Epoch 00037: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.2787 - accuracy: 0.8712 - val_loss: 0.3890 - val_accuracy: 0.8061\n",
      "Epoch 38/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2798 - accuracy: 0.8713\n",
      "Epoch 00038: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2751 - accuracy: 0.8739 - val_loss: 0.3870 - val_accuracy: 0.8061\n",
      "Epoch 39/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2730 - accuracy: 0.8741\n",
      "Epoch 00039: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2762 - accuracy: 0.8721 - val_loss: 0.3810 - val_accuracy: 0.8121\n",
      "Epoch 40/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2768 - accuracy: 0.8787\n",
      "Epoch 00040: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2768 - accuracy: 0.8757 - val_loss: 0.3866 - val_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2741 - accuracy: 0.8730\n",
      "Epoch 00041: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2741 - accuracy: 0.8730 - val_loss: 0.3821 - val_accuracy: 0.8061\n",
      "Epoch 42/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2834 - accuracy: 0.8769\n",
      "Epoch 00042: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2784 - accuracy: 0.8801 - val_loss: 0.3998 - val_accuracy: 0.8182\n",
      "Epoch 43/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2800 - accuracy: 0.8696\n",
      "Epoch 00043: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2799 - accuracy: 0.8694 - val_loss: 0.3874 - val_accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2716 - accuracy: 0.8787\n",
      "Epoch 00044: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2740 - accuracy: 0.8774 - val_loss: 0.3811 - val_accuracy: 0.8061\n",
      "Epoch 45/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2769 - accuracy: 0.8777\n",
      "Epoch 00045: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2775 - accuracy: 0.8766 - val_loss: 0.3852 - val_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2776 - accuracy: 0.8722\n",
      "Epoch 00046: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2753 - accuracy: 0.8748 - val_loss: 0.3941 - val_accuracy: 0.8000\n",
      "Epoch 47/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.8714\n",
      "Epoch 00047: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2785 - accuracy: 0.8721 - val_loss: 0.3854 - val_accuracy: 0.8000\n",
      "Epoch 48/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2711 - accuracy: 0.8741\n",
      "Epoch 00048: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2701 - accuracy: 0.8748 - val_loss: 0.3970 - val_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2724 - accuracy: 0.8739\n",
      "Epoch 00049: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2724 - accuracy: 0.8739 - val_loss: 0.3766 - val_accuracy: 0.8061\n",
      "Epoch 50/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2753 - accuracy: 0.8684\n",
      "Epoch 00050: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2722 - accuracy: 0.8677 - val_loss: 0.3796 - val_accuracy: 0.8061\n",
      "Epoch 51/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2716 - accuracy: 0.8741\n",
      "Epoch 00051: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2691 - accuracy: 0.8757 - val_loss: 0.3804 - val_accuracy: 0.8061\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.8748\n",
      "Epoch 00052: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2682 - accuracy: 0.8748 - val_loss: 0.3824 - val_accuracy: 0.8061\n",
      "Epoch 53/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2730 - accuracy: 0.8787\n",
      "Epoch 00053: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2697 - accuracy: 0.8801 - val_loss: 0.3807 - val_accuracy: 0.8061\n",
      "Epoch 54/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2764 - accuracy: 0.8686\n",
      "Epoch 00054: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2766 - accuracy: 0.8668 - val_loss: 0.3811 - val_accuracy: 0.8061\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2670 - accuracy: 0.8739\n",
      "Epoch 00055: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2670 - accuracy: 0.8739 - val_loss: 0.3768 - val_accuracy: 0.8061\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2690 - accuracy: 0.8721\n",
      "Epoch 00056: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2690 - accuracy: 0.8721 - val_loss: 0.3796 - val_accuracy: 0.8061\n",
      "Epoch 57/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2699 - accuracy: 0.8750\n",
      "Epoch 00057: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2721 - accuracy: 0.8730 - val_loss: 0.3826 - val_accuracy: 0.8061\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2662 - accuracy: 0.8819\n",
      "Epoch 00058: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2662 - accuracy: 0.8819 - val_loss: 0.3762 - val_accuracy: 0.8061\n",
      "Epoch 59/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2656 - accuracy: 0.8750\n",
      "Epoch 00059: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2652 - accuracy: 0.8748 - val_loss: 0.3907 - val_accuracy: 0.8000\n",
      "Epoch 60/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2713 - accuracy: 0.8750\n",
      "Epoch 00060: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2673 - accuracy: 0.8766 - val_loss: 0.4124 - val_accuracy: 0.8000\n",
      "Epoch 61/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2656 - accuracy: 0.8732\n",
      "Epoch 00061: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2669 - accuracy: 0.8721 - val_loss: 0.3812 - val_accuracy: 0.8121\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2624 - accuracy: 0.8739\n",
      "Epoch 00062: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.2624 - accuracy: 0.8739 - val_loss: 0.3760 - val_accuracy: 0.8061\n",
      "Epoch 63/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2609 - accuracy: 0.8769\n",
      "Epoch 00063: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.2671 - accuracy: 0.8757 - val_loss: 0.3907 - val_accuracy: 0.7697\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2698 - accuracy: 0.8703\n",
      "Epoch 00064: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2698 - accuracy: 0.8703 - val_loss: 0.3880 - val_accuracy: 0.8061\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2609 - accuracy: 0.8783\n",
      "Epoch 00065: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2609 - accuracy: 0.8783 - val_loss: 0.3737 - val_accuracy: 0.8182\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2634 - accuracy: 0.8659\n",
      "Epoch 00066: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2634 - accuracy: 0.8659 - val_loss: 0.3766 - val_accuracy: 0.7939\n",
      "Epoch 67/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2677 - accuracy: 0.8741\n",
      "Epoch 00067: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2677 - accuracy: 0.8748 - val_loss: 0.3746 - val_accuracy: 0.8121\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2618 - accuracy: 0.8739\n",
      "Epoch 00068: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2618 - accuracy: 0.8739 - val_loss: 0.4047 - val_accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2646 - accuracy: 0.8786\n",
      "Epoch 00069: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2644 - accuracy: 0.8792 - val_loss: 0.3773 - val_accuracy: 0.7636\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2576 - accuracy: 0.8837\n",
      "Epoch 00070: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2576 - accuracy: 0.8837 - val_loss: 0.3982 - val_accuracy: 0.8242\n",
      "Epoch 71/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2673 - accuracy: 0.8884\n",
      "Epoch 00071: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2661 - accuracy: 0.8890 - val_loss: 0.3940 - val_accuracy: 0.8000\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.8730\n",
      "Epoch 00072: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2607 - accuracy: 0.8730 - val_loss: 0.3770 - val_accuracy: 0.8061\n",
      "Epoch 73/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2582 - accuracy: 0.8807\n",
      "Epoch 00073: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2612 - accuracy: 0.8792 - val_loss: 0.4052 - val_accuracy: 0.7697\n",
      "Epoch 74/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2665 - accuracy: 0.8778\n",
      "Epoch 00074: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2649 - accuracy: 0.8774 - val_loss: 0.3716 - val_accuracy: 0.8121\n",
      "Epoch 75/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2547 - accuracy: 0.8821\n",
      "Epoch 00075: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2568 - accuracy: 0.8819 - val_loss: 0.3709 - val_accuracy: 0.8121\n",
      "Epoch 76/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2587 - accuracy: 0.8833\n",
      "Epoch 00076: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2581 - accuracy: 0.8845 - val_loss: 0.3837 - val_accuracy: 0.7758\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2584 - accuracy: 0.8810\n",
      "Epoch 00077: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2584 - accuracy: 0.8810 - val_loss: 0.3889 - val_accuracy: 0.8061\n",
      "Epoch 78/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2599 - accuracy: 0.8741\n",
      "Epoch 00078: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2609 - accuracy: 0.8748 - val_loss: 0.3695 - val_accuracy: 0.8121\n",
      "Epoch 79/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2496 - accuracy: 0.8888\n",
      "Epoch 00079: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2556 - accuracy: 0.8863 - val_loss: 0.3973 - val_accuracy: 0.8000\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.8757\n",
      "Epoch 00080: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.2620 - accuracy: 0.8757 - val_loss: 0.3747 - val_accuracy: 0.8061\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2550 - accuracy: 0.8801\n",
      "Epoch 00081: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.2550 - accuracy: 0.8801 - val_loss: 0.3806 - val_accuracy: 0.8121\n",
      "Epoch 82/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2573 - accuracy: 0.8833\n",
      "Epoch 00082: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.2538 - accuracy: 0.8845 - val_loss: 0.3882 - val_accuracy: 0.8061\n",
      "Epoch 83/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2600 - accuracy: 0.8821\n",
      "Epoch 00083: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.2599 - accuracy: 0.8828 - val_loss: 0.3920 - val_accuracy: 0.7636\n",
      "Epoch 84/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2566 - accuracy: 0.8787\n",
      "Epoch 00084: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2561 - accuracy: 0.8792 - val_loss: 0.3774 - val_accuracy: 0.8000\n",
      "Epoch 85/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2534 - accuracy: 0.8869\n",
      "Epoch 00085: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.2549 - accuracy: 0.8845 - val_loss: 0.3787 - val_accuracy: 0.8000\n",
      "Epoch 86/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2546 - accuracy: 0.8824\n",
      "Epoch 00086: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.2499 - accuracy: 0.8845 - val_loss: 0.3689 - val_accuracy: 0.8121\n",
      "Epoch 87/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2529 - accuracy: 0.8824\n",
      "Epoch 00087: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2494 - accuracy: 0.8837 - val_loss: 0.3968 - val_accuracy: 0.7697\n",
      "Epoch 88/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2559 - accuracy: 0.8768\n",
      "Epoch 00088: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2547 - accuracy: 0.8774 - val_loss: 0.3799 - val_accuracy: 0.8000\n",
      "Epoch 89/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2536 - accuracy: 0.8860\n",
      "Epoch 00089: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2509 - accuracy: 0.8881 - val_loss: 0.3693 - val_accuracy: 0.8121\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2549 - accuracy: 0.8739\n",
      "Epoch 00090: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2549 - accuracy: 0.8739 - val_loss: 0.3704 - val_accuracy: 0.8061\n",
      "Epoch 91/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2527 - accuracy: 0.8704\n",
      "Epoch 00091: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2500 - accuracy: 0.8739 - val_loss: 0.3719 - val_accuracy: 0.8121\n",
      "Epoch 92/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2529 - accuracy: 0.8833\n",
      "Epoch 00092: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2507 - accuracy: 0.8845 - val_loss: 0.3693 - val_accuracy: 0.8121\n",
      "Epoch 93/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2494 - accuracy: 0.8848\n",
      "Epoch 00093: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2482 - accuracy: 0.8854 - val_loss: 0.3722 - val_accuracy: 0.8061\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2472 - accuracy: 0.8872\n",
      "Epoch 00094: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2472 - accuracy: 0.8872 - val_loss: 0.3706 - val_accuracy: 0.8061\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2480 - accuracy: 0.8828\n",
      "Epoch 00095: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.2480 - accuracy: 0.8828 - val_loss: 0.3735 - val_accuracy: 0.8061\n",
      "Epoch 96/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2415 - accuracy: 0.8864\n",
      "Epoch 00096: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2466 - accuracy: 0.8854 - val_loss: 0.3707 - val_accuracy: 0.8061\n",
      "Epoch 97/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2427 - accuracy: 0.8842\n",
      "Epoch 00097: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2458 - accuracy: 0.8845 - val_loss: 0.3698 - val_accuracy: 0.8061\n",
      "Epoch 98/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2436 - accuracy: 0.8833\n",
      "Epoch 00098: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2474 - accuracy: 0.8819 - val_loss: 0.3724 - val_accuracy: 0.8061\n",
      "Epoch 99/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2488 - accuracy: 0.8824\n",
      "Epoch 00099: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2488 - accuracy: 0.8810 - val_loss: 0.3706 - val_accuracy: 0.8061\n",
      "Epoch 100/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2473 - accuracy: 0.8897\n",
      "Epoch 00100: val_accuracy did not improve from 0.83030\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2466 - accuracy: 0.8890 - val_loss: 0.3714 - val_accuracy: 0.8061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f044ba4be10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=x_samp,\n",
    "    y=y_samp,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=verbosity,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[checkpointer, LR_Scheduler, tb]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for GEN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           S       0.86      1.00      0.92       140\n",
      "           R       1.00      0.08      0.15        25\n",
      "\n",
      "    accuracy                           0.86       165\n",
      "   macro avg       0.93      0.54      0.54       165\n",
      "weighted avg       0.88      0.86      0.81       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=load_model(checkpoints)\n",
    "preds=model.predict(x_test)\n",
    "print(\"Result for {}\".format(Drug_name))\n",
    "print(classification_report(y_test.argmax(-1),preds.argmax(-1),target_names=['S','R']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_to_csv(res, bacteria, mode, encoding, method, drug_name):\n",
    "    tp = []\n",
    "    for k in res.keys():\n",
    "        if k != 'accuracy':\n",
    "            tp.append(list(res[k].values()))\n",
    "        else:\n",
    "            tp.append([np.nan, np.nan, res[k], res['macro avg']['support']])\n",
    "    tp = pd.DataFrame(tp, index=res.keys(), columns=res[\"S\"].keys())\n",
    "    tp.to_csv(f\"results/{bacteria}/{encoding}/{bacteria}_{mode}_{encoding}_{method}_{drug_name}.csv\", index=True, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = classification_report(y_test.argmax(-1), preds.argmax(-1), target_names=['S', 'R'], output_dict=True)\n",
    "res_to_csv(res, encoding=Encoding, mode=Mode, method=Method, drug_name=Drug_name, bacteria=Bacteria)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9e83ed16f81a8e2145c5b76006e38f35c412e8be0cae4deba529a0756310e81"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('torchhwk': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
